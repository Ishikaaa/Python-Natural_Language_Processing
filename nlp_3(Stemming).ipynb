{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the form of data pre-processing. It is not really the form of normalization. \n",
    "Its idea is to take words and take the root stem of words. \n",
    "For e.g. - stem - writing\n",
    "A stemming algorithm reduces the words. For e.g. - “chocolates”, “chocolatey”, “choco” to the root word. \n",
    "Why we need stem --- \n",
    "A lot of times we are going to have variations of words based on their stems. \n",
    "After stemming, meaning of word remains same. \n",
    "For e.g. - I was taking a ride in the car.\n",
    "           I was riding in the car. \n",
    "        --Meaning of both sentences is same. Difference in sentence comes when word comes ride and riding \n",
    "If we will not stemming then there will be huge database and time complexity & space complexity will incerease.\n",
    "Advanteges of stemming - \n",
    "1. It reduces time and space complexity. \n",
    "2. It reduces inefficiency. \n",
    "3. It reduces redundancy(no longer useful)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An algorithm used for nlp is called porter stemmer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "# there are many stemmers other than PorterStemmer. You can try that also. Porter Stemmer is actually pretty dam good \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(\"Modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "example_words=['python','pythonize','pythoning','pythonly','pythoner']\n",
    "for i in example_words:\n",
    "    print(ps.stem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It\n",
      "is\n",
      "veri\n",
      "import\n",
      "to\n",
      "be\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "onc\n",
      "you\n",
      "learn\n",
      "pythonn\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "example_sentence=\"It is very important to be pythonly while you are pythoning with python. All pythoners have pythoned once you learn pythonn.\"\n",
    "wordss=word_tokenize(example_sentence)\n",
    "for i in wordss:\n",
    "    print(ps.stem(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
